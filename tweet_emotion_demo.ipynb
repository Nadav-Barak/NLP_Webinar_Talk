{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "619194a7-2402-4e7b-8e10-2595197a44d8",
   "metadata": {},
   "source": [
    "In this notebook we will go over:\n",
    "1. Creating a TextData object and auto calculating properties\n",
    "2. Data integrity checks\n",
    "3. Drift and model evaluation checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd112614-f5f6-41de-a597-89b806ac462c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25bd1e77-e29b-494a-bb0a-e1689b92b4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deepchecks.nlp.text_data import TextData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16bc0c-a206-49f8-9e6d-5eac5c3bf092",
   "metadata": {},
   "source": [
    "In this tutorial we will use the tweet emotion dataset, containing tweets and metadata on the users who wrote them. </br>\n",
    "Our goal will be to create a model that given a tweet classify its emotion in one of 4 categories: 'happiness', 'anger', 'optimism' and 'sadness'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c00d26-2f82-4797-a3fb-12425854c579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>days_on_platform</th>\n",
       "      <th>user_region</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
       "      <td>24.97</td>\n",
       "      <td>Male</td>\n",
       "      <td>2729</td>\n",
       "      <td>Middle East/Africa</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
       "      <td>21.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>1376</td>\n",
       "      <td>Asia Pacific</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tiller and breezy should do a collab album. Ra...</td>\n",
       "      <td>37.29</td>\n",
       "      <td>Female</td>\n",
       "      <td>3853</td>\n",
       "      <td>Americas</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  user_age  gender  \\\n",
       "2  No but that's so cute. Atsu was probably shy a...     24.97    Male   \n",
       "3  Rooneys fucking untouchable isn't he? Been fuc...     21.66    Male   \n",
       "7  Tiller and breezy should do a collab album. Ra...     37.29  Female   \n",
       "\n",
       "   days_on_platform         user_region      label  \n",
       "2              2729  Middle East/Africa  happiness  \n",
       "3              1376        Asia Pacific      anger  \n",
       "7              3853            Americas  happiness  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepchecks.nlp.datasets.classification import tweet_emotion\n",
    "\n",
    "train, test = tweet_emotion.load_data(data_format='DataFrame')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad336eb2-1d67-4c19-a7ce-80d230f29f2b",
   "metadata": {},
   "source": [
    "## Create TextData Objects (A Deepchecks' Artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88bb843-9981-440d-9617-16fb9ab0d2a9",
   "metadata": {},
   "source": [
    "Deepchecks' TextData object contain the text samples, labels and possibly also properties and metadata. </br>\n",
    "it stores cache to save time between repeated computations and contain functionalities for input validations and sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7332e3-625f-420a-85a1-3a28825a098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TextData(train.text, label=train['label'], task_type='text_classification',\n",
    "                 index=train.index, metadata=train.drop(columns=['label', 'text']))\n",
    "test = TextData(test.text, label=test['label'], task_type='text_classification',\n",
    "                index=test.index, metadata=test.drop(columns=['label', 'text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f819dd41-70fd-4bd8-8269-0888ad749872",
   "metadata": {},
   "source": [
    "## Calculating Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61daebc6-2904-446b-a7f4-b00aebfc729a",
   "metadata": {},
   "source": [
    "Some of Deepchecks' checks uses properties of the text samples for varieus calculations. </br>\n",
    "Deepcheck have a wide varity of such properties, some simple and some that rely on external models and are more heavy to run. </br>\n",
    "In order for Deepcheck's checks to be able to acess the properties they be stored within the TextData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f934439-7783-4693-b35e-17df439262a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Length</th>\n",
       "      <th>Average Word Length</th>\n",
       "      <th>Max Word Length</th>\n",
       "      <th>% Special Characters</th>\n",
       "      <th>Language</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Toxicity</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>Formality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>4.277778</td>\n",
       "      <td>8</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.349153</td>\n",
       "      <td>0.204132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>6.923077</td>\n",
       "      <td>18</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>en</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.995803</td>\n",
       "      <td>0.176892</td>\n",
       "      <td>0.036638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Text Length  Average Word Length  Max Word Length  % Special Characters  \\\n",
       "2           94             4.277778                8              0.021277   \n",
       "3          102             6.923077               18              0.049020   \n",
       "\n",
       "  Language  Sentiment  Subjectivity  Toxicity   Fluency  Formality  \n",
       "2       en        0.0          0.75  0.009497  0.349153   0.204132  \n",
       "3       en       -0.8          0.90  0.995803  0.176892   0.036638  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properties can be either either calculated directly by Deepchecks or imported for other sources in appropriate foramt\n",
    "\n",
    "# train.calculate_default_properties(include_long_calculation_properties=True)\n",
    "# test.calculate_default_properties(include_long_calculation_properties=True)\n",
    "\n",
    "train.set_properties(pd.read_csv('train_properties.csv', index_col=0))\n",
    "test.set_properties(pd.read_csv('test_properties.csv', index_col=0))\n",
    "\n",
    "train.properties.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee6cf2a-52d4-4b6e-9340-684b44aa4884",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Integrity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac74869-51d1-4e45-9aa7-ff9a6576d454",
   "metadata": {},
   "source": [
    "We will start by doing some perlimanery integrity check to validate the text formatting. </br>\n",
    "It is recommended to do this step before model training as it may imply additional data engeneering is required. </br>\n",
    "\n",
    "We will run the TextPropertyOutliers check aim to detect outlier based on different properties Deepchecks calculate on each text sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deaf8dc-7b73-4709-a6b9-e91295b7888a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Integrity #1: Text outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff2c7c9-716d-4f2c-972e-34cd430e1d34",
   "metadata": {},
   "source": [
    "From the result we can derive several insights: </br>\n",
    "    1. hashtags ('#...') are usally several words written togther without spaces - we might consider splitting them before feeding the tweet to a model</br>\n",
    "    2. In some instances users deliberately misspell words, for example '!' instead of the letter 'l' or 'okayyyyyyyyyy'</br>\n",
    "    3. The majority of the data is in english but not all. If we want a classfier that is multi lenguial we should collect more data, otherwise we may consider </br>\n",
    "       dropping tweets in other languighes from our dataset before training our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a80996d5-3214-44e9-b05b-7880d633b39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f77bf5674c43279e54408bbc5f6d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4><b>Text Property Outliers</b></h4>'), HTML(value='<p>Find outliers images with …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.nlp.checks import TextPropertyOutliers\n",
    "\n",
    "check = TextPropertyOutliers(iqr_scale=3)\n",
    "res = check.run(train)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe07e30-5952-4527-a209-794a2b2e2ace",
   "metadata": {},
   "source": [
    "### Integrity #2: Property-Label Correlation (Shortcut Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a63494-b9d7-4687-b753-fea0ba499d85",
   "metadata": {},
   "source": [
    "Next integrity check verifies the data does not contain any shortcuts the model can fixate on during the learning process. </br> \n",
    "For more information about shortcut learning see: https://towardsdatascience.com/shortcut-learning-how-and-why-models-cheat-1b37575a159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b891e86-4bc5-4573-b08d-9d510d8105a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34a2eb56fdb4be59a85305f3c33a957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4><b>Property-Label Correlation</b></h4>'), HTML(value='<p>Return the PPS (Predic…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.nlp.checks import PropertyLabelCorrelation\n",
    "\n",
    "check = PropertyLabelCorrelation(properties_to_ignore=['Sentiment'])\n",
    "check.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994becf-e2e4-48fd-ba57-9173b8005060",
   "metadata": {},
   "source": [
    "# Drift & Model Evalution Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b20a8e-8004-4a7b-9b5e-c291ac8731de",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading precalculated model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4195110c-d9b8-4a30-931c-88a1dab97b6a",
   "metadata": {},
   "source": [
    "The checks below require model predictions and can be supplied via the relevant arguments in the ``run`` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb378a5-a5d1-45e4-a305-93dea2059e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = tweet_emotion.load_precalculated_predictions(pred_format='predictions')[train.index]\n",
    "test_preds = tweet_emotion.load_precalculated_predictions(pred_format='predictions')[test.index]\n",
    "\n",
    "train_probas = tweet_emotion.load_precalculated_predictions(pred_format='probabilities')[train.index]\n",
    "test_probas = tweet_emotion.load_precalculated_predictions(pred_format='probabilities')[test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3199213e-064a-47ce-a1f5-4bd6317c1929",
   "metadata": {},
   "source": [
    "When deploying a trained model into production is crucial to verify that the data enviroment is similar to the one the model was trained in. </br>\n",
    "This can be done by monitoring for drift in the data, predictions and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbfbf8-2e4d-4b78-b5f1-f35096529955",
   "metadata": {},
   "source": [
    "### Drift & Model Evalution #1: Prediction Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86283377-96c7-43f4-8a7b-127fa8758d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - Could not find model's classes, using the observed classes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a07f089673243d18589d2a8227c63d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4><b>Prediction Drift</b></h4>'), HTML(value='<p>    Calculate prediction drift b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.nlp.checks import PredictionDrift\n",
    "\n",
    "check = PredictionDrift().add_condition_drift_score_less_than(0.1)\n",
    "check.run(train, test, train_predictions=list(train_preds), test_predictions=list(test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac549-5d87-4d1f-b861-48fe67b2d8ca",
   "metadata": {},
   "source": [
    "### Drift & Model Evalution #2: Label Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da7e76f-1aeb-495e-a268-1ed9839bcca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee1247280644331ae44ced23cacb3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4><b>Train Test Label Drift</b></h4>'), HTML(value='<p>    Calculate label drift …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.nlp.checks import LabelDrift\n",
    "\n",
    "check = LabelDrift().add_condition_drift_score_less_than(0.1)\n",
    "check.run(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb325a-8c7a-4704-9d83-1d4497fa835b",
   "metadata": {},
   "source": [
    "We can see that in our test set, 16% of the data belongs to the class of optimism which contain only 3% of the training data. </br>\n",
    "The Prediction drift check tells us that from our model point of view there wasnt a significant change in the data distribution </br> \n",
    "meaning we are most likely dealing with a case of Concept Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e3766-fd9d-4a97-8320-6999eb0a17e1",
   "metadata": {},
   "source": [
    "Since the 'Optimism' class is rare in our training set it is possible that some of the optimism tweets found in the test set are underrepresented in the training set </br>\n",
    "and therefore our model will fail to classify them. </br>\n",
    "\n",
    "We can verify this assumption by looking at our model confusion matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e760e900-9840-4d23-a868-e67d6717aea3",
   "metadata": {},
   "source": [
    "### Drift & Model Evalution #3: Label Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ddf5b9-5484-48ff-a902-fe15edf1e0a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - Could not find model's classes, using the observed classes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4fc81301c84083814f99ceecc108e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4><b>Confusion Matrix Report</b></h4>'), HTML(value='<p>Calculate the confusion m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.nlp.checks import ConfusionMatrixReport\n",
    "\n",
    "check = ConfusionMatrixReport(normalize_display=False)\n",
    "result = check.run(test, predictions=list(test_preds))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c9f478-2d3a-4a78-bc3e-7f21e642656b",
   "metadata": {},
   "source": [
    "As we can see, our model does a really bad job in classifing tweets from the Optimism class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d7d6f-b437-4018-989e-8afdab509d2f",
   "metadata": {},
   "source": [
    "# Metadata Based Segmentation: Looking for Weak Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f8a1dd3-b151-447e-aaee-57be23c3b0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>days_on_platform</th>\n",
       "      <th>user_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.73</td>\n",
       "      <td>Male</td>\n",
       "      <td>5614</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.29</td>\n",
       "      <td>Female</td>\n",
       "      <td>4308</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.07</td>\n",
       "      <td>Female</td>\n",
       "      <td>4631</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_age  gender  days_on_platform user_region\n",
       "0     30.73    Male              5614    Americas\n",
       "1     42.29  Female              4308      Europe\n",
       "4     35.07  Female              4631      Europe"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In our use case the metadata columns are information on the user that wrote the tweet\n",
    "\n",
    "test.metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b815bbc3-58fc-4115-a362-2b12b7eed70c",
   "metadata": {},
   "source": [
    "Next, we will use the metadata columns of user related information to try and **autometically** detect significant data segments on which our model performs badly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48eb97-d47c-4087-a29d-4d8ee2a2623d",
   "metadata": {},
   "source": [
    "### Drift & Model Evalution #4: Metadata Segments Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3601fd02-6f47-4850-a452-4b211053ef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - Could not find model's classes, using the observed classes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9489148adf9e4f658fa3876ed74edea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4><b>Metadata Segments Performance</b></h4>'), HTML(value='<p>Search for segments…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.nlp.checks import MetadataSegmentsPerformance\n",
    "\n",
    "check = MetadataSegmentsPerformance()\n",
    "\n",
    "res = check.run(test, predictions=list(test_preds), probabilities=test_probas)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e262f235-c5d8-43b8-8144-d9414ca5d3a6",
   "metadata": {},
   "source": [
    "# Properties Based Segmentation: Looking for Weak Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9cc775-fb7a-48ac-bdd3-8f72e5f288eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Drift & Model Evalution #5: Properties Segments Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa69da95-5bd7-4f99-a0d8-4b965b846784",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - Could not find model's classes, using the observed classes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f845d440b84198bb9eb9817f0cd7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4><b>Property Segments Performance</b></h4>'), HTML(value='<p>Search for segments…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.nlp.checks import PropertySegmentsPerformance\n",
    "\n",
    "check = PropertySegmentsPerformance() #segment_minimum_size_ratio=0.3, categorical_aggregation_threshold=0.1\n",
    "check.run(test, predictions=list(test_preds), probabilities=test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f52143-7006-409a-9801-a5ec5d54c0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab87126-7305-4806-87a8-e0fd6cebe3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepcheck_venv",
   "language": "python",
   "name": "deepcheck_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
